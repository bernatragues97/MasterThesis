---
title: "MASTER THESIS CODE_copy"
output: html_notebook
---

#Libraries:

```{r}

library(recommenderlab)
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(ggmap)
library(leaflet)
library(naniar)
library(caret)

#Avoid scientific notation
options(scipen=999)

```

#I. INTRODUCTION

##A. Background 

##B. Purpose 

##C. Scope

#I. DATA LOADING, DATA DESCRIPTION AND EXPLORATORY DATA ANALYSIS

##A. Data source

Data scraped from TripAdvisor.com. Two data sets are retrieved at the end of the web scrapping process.

##B. Loading data into R and preparing dataframes

We will import 2 data sets, one for the reviews (ratings) and one for the restaurants information.

```{r}

df_reviews <- read.csv("reviews.csv")
df_restaurants <- read.csv("restaurant_features.csv")

```

##C. Data description

For Ratings dataset:

```{r}

dim(df_reviews) #This function returns the dimensions (number of rows and columns) of a data frame.

summary(df_reviews) #This function provides a summary of the central tendency, dispersion, and distribution of all numeric variables in a data frame. It gives the minimum, 1st quartile, median (2nd quartile), mean, 3rd quartile, and maximum values of each numeric variable, as well as the number of missing values.

str(df_reviews) #This function provides the structure of a data frame, showing the variable names, data types, and the first few observations of each variable.

```

For Restaurants Dataset:

```{r}

dim(df_restaurants)

summary(df_restaurants)

str(df_restaurants)

```

##D. Descriptive statistics amd Data visualization

USER-ITEM RATINGS DATASET

Plot general distribution of customer-restaurant ratings:

```{r}
# Create histogram
ggplot(df_reviews, aes(x = rating)) +
  geom_histogram(binwidth = 1, fill = "black", color = "white") +
  labs(title = "Histogram of Ratings", x = "Ratings", y = "Frequency") +
  theme_minimal() +  theme(plot.title = element_text(size = 16, hjust = 0.5),#, face = "bold"),
        axis.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.text = element_text(size = 12, hjust = 0.5), axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))


```

Plot for reviews dates:

```{r}

# Convert character strings (i.e. "March 15, 2023") to Date format
df_reviews$review_date <- as.Date(df_reviews$review_date, format = "%B %d, %Y")

#Histogram plot
ggplot(df_reviews, aes(x = review_date, y = ..count..)) +
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue", alpha = 0.5) +
  labs(x = "Review Date", y = "Review Count", title = "Continuous Histogram of Reviews by Date") +
  theme_minimal() + theme(plot.title = element_text(size = 16, hjust = 0.5),#, face = "bold"),
        axis.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.text = element_text(size = 12, hjust = 0.5), axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))

```

Amount of reviews per user:

```{r}
# Group by member_id and calculate the count of reviews
df_reviews_01 <- df_reviews %>%
  group_by(member_id) %>%
  summarise(review_count = n())

#Amount of users with at least one review in the dataset
dim(df_reviews_01)

# Create the density plot
ggplot(df_reviews_01, aes(x = review_count)) +
  geom_density(fill = "black", alpha = 0.5) +
  labs(x = "Review Count", y = "Density") +
  ggtitle("Density Plot of Review Count per Member") +
  theme_minimal() + theme(plot.title = element_text(size = 16, hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.text = element_text(size = 12, hjust = 0.5), axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))

# Create boxplot
ggplot(df_reviews_01, aes(x = "", y = review_count)) +
  geom_boxplot(fill = "white", color = "black") +
  labs(x = "User", y = "Review Count") +
  ggtitle("Boxplot of Review Count per User") +
  theme_minimal() + theme(plot.title = element_text(size = 16, hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.text = element_text(size = 12, hjust = 0.5), axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))

```

RESTAURANT FEATURES DATASET

Amount of reviews per restaurant:

```{r}

# Create density plot
ggplot(df_restaurants, aes(x = nreviews)) +
  geom_density(fill = "black", alpha = 0.5) +
  labs(x = "Review Count", y = "Density") +
  ggtitle("Density Plot of Review Count per Restaurant") +
  theme_minimal() + theme(plot.title = element_text(size = 16, hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.text = element_text(size = 12, hjust = 0.5), axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))

# Create boxplot
ggplot(df_restaurants, aes(y = nreviews)) +
  geom_boxplot(fill = "white", color = "black") +
  labs(x = "Restaurant", y = "Review Count") +
  ggtitle("Boxplot of Review Count per Restaurant") +
  theme_minimal() + theme(plot.title = element_text(size = 16, hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.text = element_text(size = 12, hjust = 0.5), axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))

```

Average restaurants ratings histogram

```{r}

#Create a histogram of "avgrade"
ggplot(df_restaurants, aes(x = avgrade)) +
  geom_histogram(binwidth = 1, fill = "black", color = "grey") +
  labs(x = "Average Grade", y = "Frequency", title = "Distribution of Restaurants Average Grades") +
  theme_minimal() + theme(plot.title = element_text(size = 16, hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.text = element_text(size = 12, hjust = 0.5), axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))

```

Map plot with restaurants location

```{r}

# Set API key for ggmap (replace 'YOUR_API_KEY' with your actual API key)
register_google(key = 'AIzaSyAkN0rEp7OkCF6_6d06tdVipBQTidq0yNc')

# Filter out rows with missing or improperly formatted values in the "location" variable
df_restaurants <- df_restaurants[!is.na(df_restaurants$location) & grepl("^\\d+\\.\\d+,\\d+\\.\\d+$", df_restaurants$location), ]

# Extract latitude and longitude from the "location" variable
df_restaurants$latitude <- as.numeric(substring(df_restaurants$location, 1, regexpr(",", df_restaurants$location) - 1))
df_restaurants$longitude <- as.numeric(substring(df_restaurants$location, regexpr(",", df_restaurants$location) + 1))

# Get the map of Aarhus using ggmap
aarhus_map <- get_map(location = "Aarhus, Denmark", zoom = 13, maptype = "roadmap")

# Create the ggplot2 plot with ggmap
ggmap(aarhus_map) +
  geom_point(data = df_restaurants, aes(x = longitude, y = latitude), size = 1, color = "blue") +
  labs(title = "Scrapped restaurants mapped",
       x = "Longitude", y = "Latitude") +
  theme_minimal() + theme(plot.title = element_text(size = 12, hjust = 0.5),#, face = "bold"),
        axis.title = element_text(size = 10, face = "bold", hjust = 0.5),
        axis.text = element_text(size = 10, hjust = 0.5), axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))
```

Restaurant price distribution:

```{r}

# Replace all occurrences of "#NA" with "NA" in the "price" variable
df_restaurants$price <- gsub("#N/A", "N/A", df_restaurants$price)

# Define a black-and-white color palette with 4 shades of gray
my_colors <- c("#000000", "#404040", "#808080", "#FFFFFF")

# Create a bar chart of price range with black-and-white color palette
ggplot(df_restaurants, aes(x = price, fill = price)) +
  geom_bar(stat = "count", color = "black") +
  labs(x = "Price Range", y = "Count") +
  ggtitle("Distribution of Price Range") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = my_colors) + theme(plot.title = element_text(size = 16, hjust = 0.5),#, face = "bold"),
        axis.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.text = element_text(size = 12, hjust = 0.5), axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))

```

##E. Data quality

Impute NA to missing values and values N/A

```{r}

df_reviews <- replace(df_reviews, df_reviews == "", NA)

df_restaurants <- replace(df_restaurants, df_restaurants == "NA", NA)

df_restaurants <- replace(df_restaurants, df_restaurants == "N/A", NA)

df_restaurants <- replace(df_restaurants, df_restaurants == "", NA)

```

Missing data:

```{r}

#Checking missing entries with naniar package

#Create missing values plot for REVIEWS DATASET
missing_plot <- gg_miss_var(df_reviews) +
  labs(title = "Missing Values Plot",
       x = "Variable",
       y = "df_reviews") +
  theme_minimal() + theme(plot.title = element_text(size = 16, hjust = 0.5),#, face = "bold"),
        axis.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.text = element_text(size = 12, hjust = 0.5), axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))

# Display the plot
print(missing_plot)

#Create missing values plot for RESTAURANT FEATURES DATASET

missing_plot <- gg_miss_var(df_restaurants) +
  labs(title = "Missing Values Plot",
       x = "Variable",
       y = "df_restaurants") +
  theme_minimal() + theme(plot.title = element_text(size = 16, hjust = 0.5),#, face = "bold"),
        axis.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.text = element_text(size = 12, hjust = 0.5), axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))

# Display the plot
print(missing_plot)

#Delete advantages column
df_restaurants <- df_restaurants[, !colnames(df_restaurants) %in% "advantages"]

```


#II. DATA PREPARATION

##A. Data selection - Inclusion and exclusion

Drop all non-necessary columns for building a rating matrix and drop meals variable from the restaurant features dataset

```{r}

# Drop columns 2, 3, 4, 7, 8, 9, and 10 from df_reviews dataframe
df_ratingMatrix <- df_reviews[, -c(2, 3, 4, 7, 8, 9, 10)]

# Drop column 7 from df_restaurants dataframe
df_restaurants<- df_restaurants[, -c(2, 7, 8, 9, 10)]

```

##B. Data processing

USER-ITEM RATINGS DATASET

First, start by renaiming the variables so that we can convert the dataset into a RealRatingMatrix format by using recommenderlab R package

```{r}

# Rename variables in df_reviews
df_ratingMatrix <- rename(df_ratingMatrix, item = restaurant, user = member_id, ratings = rating)

df_ratingMatrix <- df_ratingMatrix[, c(2, 1, 3)]
                   
```


Second, Create a RealRatingMatrix object from the dataset.This object is optimized to store sparse matrices

```{r}

#Creating the rating matrix
ratingMatrix <- as(df_ratingMatrix, "realRatingMatrix")

```

View/Access the ratings matrix. Since we can not directly view a RealRatingMatrix object, we can convert it into a regular matrix to be able to display it

```{r}

# Access the ratings matrix from the realRatingMatrix object
ratings_mat <- ratingMatrix@data

# Convert the ratings matrix to a regular matrix
ratings_mat <- as.matrix(ratings_mat)

# View the ratings matrix
#ratings_mat

```

RESTAURANT FEATURES DATASET

Creating dummy variables for price variable

```{r}

# Create dummy variables for the "price" variable
df_restaurant_dummiesPrice <- dummyVars(" ~ price", data = df_restaurants) %>%
  predict(df_restaurants) %>%
  replace(is.na(.), 0)

# View the resulting dataframe with dummy variables
head(df_restaurant_dummiesPrice)

# Convert the resulting matrix to a dataframe
df_restaurant_dummiesPrice <- as.data.frame(df_restaurant_dummiesPrice)  

#Creating final dataset
df_restaurants_final <- cbind(df_restaurants, df_restaurant_dummiesPrice$pricelow, df_restaurant_dummiesPrice$pricemid, df_restaurant_dummiesPrice$pricehigh)

```

Creating dummy variables for the special diets variables

```{r}

#We only need the special_diets variable

df_restaurants_specialDiets <- df_restaurants[, -c(2,3,4)]

# Split the "special_diets" column into separate rows by comma
df_restaurants_specialDiets <- df_restaurants_specialDiets %>%
  separate_rows(special_diets, sep = ",\\s*")

# Create dummy variables for each category
df_restaurant_dummiesSpecialDiets <- df_restaurants_specialDiets %>%
  pivot_wider(names_from = special_diets, values_from = special_diets, values_fn = length, names_prefix = "special_diets_") %>%
  replace(is.na(.), 0)

# Merge both datasets
df_restaurants_final <- merge(df_restaurants_final, df_restaurant_dummiesSpecialDiets, by = "restaurant")


```

Creating dummy variables for the cuisine types

```{r}

#We only need the cuisine_types variable

df_restaurants_cuisineTypes <- df_restaurants[, -c(2,3,5)]

# Split the "special_diets" column into separate rows by comma
df_restaurants_cuisineTypes <- df_restaurants_cuisineTypes %>%
  separate_rows(cuisine_types, sep = ",\\s*")

# Create dummy variables for each category
df_restaurant_dummiesCuisineTypes <- df_restaurants_cuisineTypes %>%
  pivot_wider(names_from = cuisine_types, values_from = cuisine_types, values_fn = length, names_prefix = "cuisine_types_") %>%
  replace(is.na(.), 0)

# Merge both datasets
df_restaurants_final <- merge(df_restaurants_final, df_restaurant_dummiesCuisineTypes, by = "restaurant")

```

Cleaning final dataset

```{r}

#Delete previous variables price, cuisine_types and special_diets, as well as special_diets NA dummy and cuisine_types NA dummy
df_restaurants_final <- df_restaurants_final[, -c(2, 3, 4, 5, 12, 50)]

#Remove datasets which are no longer necessary

rm(df_restaurant_dummiesCuisineTypes, df_restaurant_dummiesPrice, df_restaurant_dummiesSpecialDiets, df_restaurants_cuisineTypes, df_restaurants_specialDiets)


```


#III. MODELING 

##COLLABORATIVE FILTERING

Start by defining the minimum amount of evaluations per user and evaluations per item

```{r}

#At least 10 items evaluated or at least 25 users for each item
rates1 <- ratingMatrix[rowCounts(ratingMatrix) >= 10, colCounts(ratingMatrix) >= 50]

```

###A. Models selection 

```{r}

#Different recommender models
recommenderRegistry$get_entries(dataType="realRatingMatrix")

```

We will be testing UBCF, IBCF, Funk SVD, LIBMF, Popular and Random algorithms available in the package. The first two to test neighborhood techniques, the two after to test matrix factorization models which should perform better for a sparse matrix problem and the last two as baseline model to compare the personalized filtering techniques results.

###B. Models training and evaluation

Create two evaluation schemes, one train-test 70/30 evaluation scheme and one 10 fold cross-validation evaluation scheme

Train/test split

```{r}

set.seed(123)
train_pct <- 0.7 #Method, train-test split
rating_threshold <- 4 # threshold rating at which we consider the item to be good
items_to_keep <- -1 # Evaluation scheme using all-but-1 items

scheme_split <- evaluationScheme(data = rates1, method = "split", train = train_pct, given = items_to_keep, k = 1, goodRating = rating_threshold)

```


####B.1 User-based Collaborative filtering 

Start by simply checking if we are able to create a set of recommendations for specific users and evaluate these recommendations. Check as well how this model performs in terms of accuracy of predictions.

```{r}

# Create a USER-based collaborative filtering recommender
recommender_UBCF <- Recommender(getData(scheme_split, "train"), "UBCF")

# Generate topNlist recommendations for each user
recs_UBCF <- predict(recommender_UBCF, getData(scheme_split, "known"), type = "topNList", n = 10)

# Extract the actual recommendations from the list
recommendations_list_UBCF <- as(recs_UBCF, "list")
for (i in seq_along(recommendations_list_UBCF)) {
  cat("User", i, "recommended items:", toString(recommendations_list_UBCF[[i]]), "\n")
}

#Calculate prediction accuracy in terms of accuracy of classifications for the generated recommendations 

calcPredictionAccuracy(recs_UBCF, getData(scheme_split, "unknown"), given = 10, goodRating = 4)

#Now we will proceed computing the accuracy of predictions

recs_ACC_UBCF <- predict(recommender_UBCF, getData(scheme_split, "known"), type = "ratings")

calcPredictionAccuracy(recs_ACC_UBCF, getData(scheme_split, "unknown"))

```

Next step is parameter tunning with the aim of improving the models. This packages includes no grid/tunning parameter tools.

Default are nn = 25 (We will try 10, 30 and 45), method = cuisine (try jaccard), normalization is already performed

```{r}

algorithms_UBCF <- list(
  "user-based jaccardNN25"     = list(name  = "UBCF", param = list(method = "jaccard")),
  "user-based cosineNN10"     = list(name  = "UBCF", param = list(method = "Cosine", nn = 10)),
  "user-based cosineNN30"     = list(name  = "UBCF", param = list(method = "Cosine", nn = 30)),
  "user-based cosineNN45"     = list(name  = "UBCF", param = list(method = "Cosine", nn = 45)),
  "user-based cosineNN25"     = list(name  = "UBCF", param = list(method = "Cosine"))
)

# Estimate the Models in terms of accuracy of predictions
results_UBCF <- recommenderlab::evaluate(scheme_split,
                                    algorithms_UBCF, 
                                    type  = "ratings")

# Let's gather the results 
avg_conf_matr_UBCF <- function(results_UBCF) {
  tmp <- results_UBCF %>%
    getConfusionMatrix()  %>%  
    as.data.frame() %>%
    select('MAE', 'MSE', 'RMSE') 
}

#Print the results all together
results_summary_UBCF <- results_UBCF %>%
  map(avg_conf_matr_UBCF) %>% # iterate function across all models
  enframe() %>% 
  unnest() 

results_summary_UBCF

# Estimate the Models in terms of accuracy of classifications
results_UBCF1 <- recommenderlab::evaluate(scheme_split,
                                    algorithms_UBCF, 
                                    type  = "topNList", 
                                    n     = c(5, 10, 20)
                                    )

# Let's gather the results 
avg_conf_matr_UBCF1 <- function(results_UBCF1) {
  tmp <- results_UBCF1 %>%
    getConfusionMatrix()  %>%  
    as.data.frame() %>%
    select('n','precision', 'recall') 
}

#Print the results all together
results_summary_UBCF1 <- results_UBCF1 %>%
  map(avg_conf_matr_UBCF1) %>% # iterate function across all models
  enframe() %>% 
  unnest() 

results_summary_UBCF1

#In general terms, the best performing algorithm is UBCF computed with cuisine similarity with 45 neighbors

```

####B.2 Item-based Collaborative filtering

Start by simply checking if we are able to create a set of recommendations for specific users and evaluate these recommendations. Check as well how this model performs in terms of accuracy of predictions.

```{r}

# Create a ITEM-based collaborative filtering recommender
recommender_IBCF <- Recommender(getData(scheme_split, "train"), "IBCF")

# Generate recommendations for a test set
recs_IBCF <- predict(recommender_IBCF, getData(scheme_split, "known"), type = "topNList", n = 10)

# Extract the actual recommendations from the list
recommendations_list_IBCF <- as(recs_IBCF, "list")
for (i in seq_along(recommendations_list_IBCF)) {
  cat("User", i, "recommended items:", toString(recommendations_list_IBCF[[i]]), "\n")
}

#This code generates the top-5 recommendations for each user in the test set using the IBCF model trained on the training set. 

calcPredictionAccuracy(recs_IBCF, getData(scheme_split, "unknown"), given = 10, goodRating = 4)

#Now we will proceed computing the accuracy of predictions

recs_ACC_IBCF <- predict(recommender_IBCF, getData(scheme_split, "known"), type = "ratings")

calcPredictionAccuracy(recs_ACC_IBCF, getData(scheme_split, "unknown"))

```

Next step is parameter tunning with the aim of improving the models.

Default are K = 30 (We will try 10, 25 and 45), method = cuisine (try jaccard), normalization is already performed

```{r}

algorithms_IBCF <- list(
  "item-based jaccard"     = list(name  = "IBCF", param = list(method = "jaccard")),
  "item-based cosineK10"     = list(name  = "IBCF", param = list(method = "Cosine", k = 10)),
  "item-based cosineK25"     = list(name  = "IBCF", param = list(method = "Cosine", k = 25)),
  "item-based cosineK45"     = list(name  = "IBCF", param = list(method = "Cosine", k = 45)),
  "item-based cosineK30"     = list(name  = "IBCF", param = list(method = "Cosine"))
)

# Estimate the Models in terms of accuracy of predictions
results_IBCF <- recommenderlab::evaluate(scheme_split,
                                    algorithms_IBCF, 
                                    type  = "ratings")

# Let's gather the results 
avg_conf_matr_IBCF <- function(results_IBCF) {
  tmp <- results_IBCF %>%
    getConfusionMatrix()  %>%  
    as.data.frame() %>%
    select('MAE', 'MSE', 'RMSE') 
}

#Print the results all together
results_summary_IBCF <- results_IBCF %>%
  map(avg_conf_matr_IBCF) %>% # iterate function across all models
  enframe() %>% 
  unnest() 

results_summary_IBCF

# Estimate the Models in terms of accuracy of classifications
results_IBCF1 <- recommenderlab::evaluate(scheme_split,
                                    algorithms_IBCF, 
                                    type  = "topNList", 
                                    n     = c(5, 10, 20)
                                    )

# Let's gather the results 
avg_conf_matr_IBCF1 <- function(results_IBCF1) {
  tmp <- results_IBCF1 %>%
    getConfusionMatrix()  %>%  
    as.data.frame() %>%
    select('n','precision', 'recall') 
}

#Print the results all together
results_summary_IBCF1 <- results_IBCF1 %>%
  map(avg_conf_matr_IBCF1) %>% # iterate function across all models
  enframe() %>% 
  unnest() 

results_summary_IBCF1

#In general terms, the best performing algorithm is UBCF computed with cuisine similarity with 45, 25 or 30 k neighbors

```


####B.3 LIBMF Matrix Factorization

Start by simply checking if we are able to create a set of recommendations for specific users and evaluate these recommendations. Check as well how this model performs in terms of accuracy of predictions.

```{r}

# Create a LIBMF collaborative filtering recommender
recommender_LIBMF <- Recommender(getData(scheme_split, "train"), "LIBMF")

# Generate recommendations for a test set
recs_LIBMF <- predict(recommender_LIBMF, getData(scheme_split, "known"), type = "topNList", n = 10)

# Extract the actual recommendations from the list
recommendations_list_LIBMF <- as(recs_LIBMF, "list")
for (i in seq_along(recommendations_list_LIBMF)) {
  cat("User", i, "recommended items:", toString(recommendations_list_LIBMF[[i]]), "\n")
}

#This code generates the top-5 recommendations for each user in the test set using the IBCF model trained on the training set. 

calcPredictionAccuracy(recs_LIBMF, getData(scheme_split, "unknown"), given = 10, goodRating = 4)

#Now we will proceed computing the accuracy of predictions

recs_ACC_LIBMF <- predict(recommender_LIBMF, getData(scheme_split, "known"), type = "ratings")

calcPredictionAccuracy(recs_ACC_LIBMF, getData(scheme_split, "unknown"))

```

Next step is parameter tunning with the aim of improving the models.

```{r}
set.seed(123)
algorithms_LIBMF <- list(
  "Matrix factorization LIBMF1"     = list(name  = "LIBMF", param = list(dim = 20)),
  "Matrix factorization LIBMF2"     = list(name  = "LIBMF", param = list(dim = 5)),
  "Matrix factorization LIBMF3"     = list(name  = "LIBMF", param = list(costp_l2 = 0.05)),
  "Matrix factorization LIBMF4"     = list(name  = "LIBMF", param = list(costq_l2 = 0.05)),
  "Matrix factorization LIBMF5"     = list(name  = "LIBMF", param = list())
)

# Estimate the Models in terms of accuracy of predictions
results_LIBMF <- recommenderlab::evaluate(scheme_split,
                                    algorithms_LIBMF, 
                                    type  = "ratings")

# Let's gather the results 
avg_conf_matr_LIBMF <- function(results_LIBMF) {
  tmp <- results_LIBMF %>%
    getConfusionMatrix()  %>%  
    as.data.frame() %>%
    select('MAE', 'MSE', 'RMSE') 
}

#Print the results all together
results_summary_LIBMF <- results_LIBMF %>%
  map(avg_conf_matr_LIBMF) %>% # iterate function across all models
  enframe() %>% 
  unnest() 

results_summary_LIBMF

# Estimate the Models in terms of accuracy of classifications
results_LIBMF1 <- recommenderlab::evaluate(scheme_split,
                                    algorithms_LIBMF, 
                                    type  = "topNList", 
                                    n     = c(5, 10, 20)
                                    )

# Let's gather the results 
avg_conf_matr_LIBMF1 <- function(results_LIBMF1) {
  tmp <- results_LIBMF1 %>%
    getConfusionMatrix()  %>%  
    as.data.frame() %>%
    select('n','precision', 'recall') 
}

#Print the results all together
results_summary_LIBMF1 <- results_LIBMF1 %>%
  map(avg_conf_matr_LIBMF1) %>% # iterate function across all models
  enframe() %>% 
  unnest() 

results_summary_LIBMF1

#In general terms, the best performing algorithm is LIMBF computed with dim = 5

```

####B.4 Funk SVD Matrix Factorization

Start by simply checking if we are able to create a set of recommendations for specific users and evaluate these recommendations. Check as well how this model performs in terms of accuracy of predictions.

```{r}

# Create a Funk SVD collaborative filtering recommender
recommender_SVDF <- Recommender(getData(scheme_split, "train"), "SVDF")

# Generate recommendations for a test set
recs_SVDF <- predict(recommender_SVDF, getData(scheme_split, "known"), type = "topNList", n = 10)

# Extract the actual recommendations from the list
recommendations_list_SVDF <- as(recs_SVDF, "list")
for (i in seq_along(recommendations_list_SVDF)) {
  cat("User", i, "recommended items:", toString(recommendations_list_SVDF[[i]]), "\n")
}

#This code generates the top-5 recommendations for each user in the test set using the IBCF model trained on the training set. 

calcPredictionAccuracy(recs_SVDF, getData(scheme_split, "unknown"), given = 10, goodRating = 4)

#Now we will proceed computing the accuracy of predictions

recs_ACC_SVDF <- predict(recommender_SVDF, getData(scheme_split, "known"), type = "ratings")

calcPredictionAccuracy(recs_ACC_SVDF, getData(scheme_split, "unknown"))

```


Next step is parameter tunning with the aim of improving the models.

```{r}

algorithms_SVDF <- list(
  "Matrix factorization SVDF1"     = list(name  = "SVDF", param = list(k = 20)),
  "Matrix factorization SVDF2"     = list(name  = "SVDF", param = list(k = 5)),
  "Matrix factorization SVDF3"     = list(name  = "SVDF", param = list(max_epochs = 300)),
  "Matrix factorization SVDF4"     = list(name  = "SVDF", param = list(lambda = 0.005)),
  "Matrix factorization SVDF5"     = list(name  = "SVDF", param = list())
)

# Estimate the Models in terms of accuracy of predictions
results_SVDF <- recommenderlab::evaluate(scheme_split,
                                    algorithms_SVDF, 
                                    type  = "ratings")

# Let's gather the results 
avg_conf_matr_SVDF <- function(results_SVDF) {
  tmp <- results_SVDF %>%
    getConfusionMatrix()  %>%  
    as.data.frame() %>%
    select('MAE', 'MSE', 'RMSE') 
}

#Print the results all together
results_summary_SVDF <- results_SVDF %>%
  map(avg_conf_matr_SVDF) %>% # iterate function across all models
  enframe() %>% 
  unnest() 

results_summary_SVDF

# Estimate the Models in terms of accuracy of classifications
results_SVDF1 <- recommenderlab::evaluate(scheme_split,
                                    algorithms_SVDF, 
                                    type  = "topNList", 
                                    n     = c(5, 10, 20)
                                    )

# Let's gather the results 
avg_conf_matr_SVDF1 <- function(results_SVDF1) {
  tmp <- results_SVDF1 %>%
    getConfusionMatrix()  %>%  
    as.data.frame() %>%
    select('n','precision', 'recall') 
}

#Print the results all together
results_summary_SVDF1 <- results_SVDF1 %>%
  map(avg_conf_matr_SVDF1) %>% # iterate function across all models
  enframe() %>% 
  unnest() 

results_summary_SVDF1

#In general terms, the best performing algorithm is SVDF computed with k = 20 which achieves almost the same MAE as SVDF with k = 5 but improving the results obtained for accuracy of classifications.

```


####B.5 Popular and Random

Start by simply checking if we are able to create a set of recommendations for specific users and evaluate these recommendations. Check as well how these models performs in terms of accuracy of predictions.

```{r}

# Create a popular recommender
recommender_POP <- Recommender(getData(scheme_split, "train"), "POPULAR")

# Generate recommendations for a test set
recs_POP <- predict(recommender_POP, getData(scheme_split, "known"), type = "topNList", n = 10)

# Extract the actual recommendations from the list
recommendations_list_POP <- as(recs_POP, "list")
for (i in seq_along(recommendations_list_POP)) {
  cat("User", i, "recommended items:", toString(recommendations_list_POP[[i]]), "\n")
}

#This code generates the top-5 recommendations for each user in the test set using the IBCF model trained on the training set. 

calcPredictionAccuracy(recs_POP, getData(scheme_split, "unknown"), given = 10, goodRating = 4)

#Now we will proceed computing the accuracy of predictions

recs_ACC_POP <- predict(recommender_POP, getData(scheme_split, "known"), type = "ratings")

calcPredictionAccuracy(recs_ACC_POP, getData(scheme_split, "unknown"))

```

```{r}

# Create a Random recommender
recommender_RANDOM <- Recommender(getData(scheme_split, "train"), "RANDOM")

# Generate recommendations for a test set
recs_RANDOM <- predict(recommender_RANDOM, getData(scheme_split, "known"), type = "topNList", n = 10)

# Extract the actual recommendations from the list
recommendations_list_RANDOM <- as(recs_RANDOM, "list")
for (i in seq_along(recommendations_list_RANDOM)) {
  cat("User", i, "recommended items:", toString(recommendations_list_RANDOM[[i]]), "\n")
}

#This code generates the top-5 recommendations for each user in the test set using the IBCF model trained on the training set. 

calcPredictionAccuracy(recs_RANDOM, getData(scheme_split, "unknown"), given = 10, goodRating = 4)

#Now we will proceed computing the accuracy of predictions

recs_ACC_RANDOM <- predict(recommender_RANDOM, getData(scheme_split, "known"), type = "ratings")

calcPredictionAccuracy(recs_ACC_RANDOM, getData(scheme_split, "unknown"))

```

####B.6 Best performing algorithms tables

```{r}

algorithms_SUMMARY <- list(
  "user-based cosineNN45"     = list(name  = "UBCF", param = list(method = "Cosine", nn = 45)),
  "item-based cosineK30"     = list(name  = "IBCF", param = list(method = "Cosine")),
  "Matrix factorization LIBMF2"     = list(name  = "LIBMF", param = list(dim = 5)),
  "Matrix factorization SVDF1"     = list(name  = "SVDF", param = list(k = 20)),
  "Popular"     = list(name  = "POPULAR", param = list()),
  "Random"     = list(name  = "RANDOM", param = list())
)

# Estimate the Models in terms of accuracy of predictions
results_SUMMARY <- recommenderlab::evaluate(scheme_split,
                                    algorithms_SUMMARY, 
                                    type  = "ratings")

# Let's gather the results 
avg_conf_matr_SUMMARY <- function(results_SUMMARY) {
  tmp <- results_SUMMARY %>%
    getConfusionMatrix()  %>%  
    as.data.frame() %>%
    select('MAE', 'MSE', 'RMSE') 
}

#Print the results all together
results_summary_SUMMARY <- results_SUMMARY %>%
  map(avg_conf_matr_SUMMARY) %>% # iterate function across all models
  enframe() %>% 
  unnest() 

results_summary_SUMMARY

# Estimate the Models in terms of accuracy of classifications
results_SUMMARY1 <- recommenderlab::evaluate(scheme_split,
                                    algorithms_SUMMARY, 
                                    type  = "topNList", 
                                    n     = c(5, 10, 20)
                                    )

# Let's gather the results 
avg_conf_matr_SUMMARY1 <- function(results_SUMMARY1) {
  tmp <- results_SUMMARY1 %>%
    getConfusionMatrix()  %>%  
    as.data.frame() %>%
    select('n','precision', 'recall') 
}

#Print the results all together
results_summary_SUMMARY1 <- results_SUMMARY1 %>%
  map(avg_conf_matr_SUMMARY1) %>% # iterate function across all models
  enframe() %>% 
  unnest() 

results_summary_SUMMARY1

#In general terms, the best performing algorithm is SVDF computed with k = 20 which achieves almost the same MAE as SVDF with k = 5 but improving the results obtained for accuracy of classifications.

```


##CONTENT-BASED RECOMMENDATION

Select users only with more than 10 reviews

```{r}

df_reviews_01 <- subset(df_reviews_01, review_count >= 10)

# Rename variable in df_reviews_01
df_reviews_01 <- rename(df_reviews_01, user = member_id)

#Select only the users with more than 25 reviews from the df_ratingMatrix
df_ratingMatrixCB <- inner_join(df_reviews_01, df_ratingMatrix, by = "user")

```

Merge the df_ratingMatrixCB with the df_restaurants_final dataset, we need to merge them through the variable restaurat/item. Convert the ratings into binary ratings

```{r}

#Rename variable in df_restaurants_final
df_restaurants_final <- rename(df_restaurants_final, item = restaurant)

df_CB <- merge(df_ratingMatrixCB, df_restaurants_final, by = "item")

#Drop column review_count

df_CB<- df_CB[, -c(3)]

#Conver ratings into binary answer like / dislike

df_CB$ratings <- ifelse(df_CB$ratings >= 4, "like", "dislike")

#Check for variable types
str(df_CB)

#Create factor variables for variables 3 until 82

df_CB <- df_CB %>%
  mutate_at(vars(3:82), factor)

# Identify columns with only one unique value and delete them, since they don't bring additional information to the model
cols_to_remove <- sapply(df_CB, function(x) length(unique(x))) == 1

# Remove identified columns from the dataframe
df_CB <- df_CB[, !cols_to_remove]

str(df_CB)


```


###A. Model selection

Since there is not build-in package for R that incorporates content-based recommendation, we need to create the models ourselves. A bayesian classifier will be implemented.

###B. Model training and evaluation

Now we need to create a Naive Bayes classifier model for each of the users, we should start by splitting the data. We create a training and a test set.
 
```{r}

# Split the data by user
user_data <- split(df_CB, df_CB$user)

# Define the percentage of data to use for testing
test_pct <- 0.3

# Create a list to store the training and test dataframes for each user
user_data_split <- list()

# Loop through each user
for (i in seq_along(user_data)) {
  
  # Split the data for the current user into training and test dataframes
  train_df <- user_data[[i]] %>%
    sample_frac(1 - test_pct, replace = FALSE)
  test_df <- user_data[[i]] %>%
    anti_join(train_df, by = c("item", "user", "ratings"))
  
  # Store the training and test dataframes for the current user in the list
  user_data_split[[i]] <- list(train_df = train_df, test_df = test_df)
  
}

# Example usage: access the training dataframe for the third user
user_data_split[[3]]$train_df

```

Now that the data is splitted, we can proceed with the modelling. We will use train-test datasets as evaluation protocol

```{r}

library(e1071)

# create an empty list to store confusion matrices
conf_matrices <- list()

# loop through each element in user_data_split
for (i in seq_along(user_data_split)) {
  
  # extract training and test data
  train_data <- user_data_split[[i]]$train_df[, 4:72]
  train_labels <- user_data_split[[i]]$train_df$ratings
  test_data <- user_data_split[[i]]$test_df[, 4:72]
  test_labels <- user_data_split[[i]]$test_df$ratings
  
  # train naive bayes model
  nb_model <- naiveBayes(train_data, train_labels)
  
  # make predictions on test data
  nb_pred <- predict(nb_model, test_data)
  
  # compute confusion matrix for this fold
  fold_cm <- table(nb_pred, test_labels)
  
  # add fold confusion matrix to list of matrices
  conf_matrices[[i]] <- fold_cm
  
}

# print the confusion matrices for each of the users
for (i in seq_along(conf_matrices)) {
  print(paste0("Confusion matrix for element ", i, ":"))
  print(conf_matrices[[i]])
}

```

Create an aggregate confusion matrix

```{r}

# create an empty confusion matrix
agg_cm <- matrix(0, nrow = length(unique(test_labels)), ncol = length(unique(test_labels)))
dimnames(agg_cm) <- dimnames(fold_cm) # set row and column names to match fold_cm

# use Reduce() function to sum all confusion matrices element-wise
agg_cm <- Reduce(`+`, conf_matrices)

# print the aggregate confusion matrix
print("Aggregate confusion matrix:")
print(agg_cm)

#Accuracy = (TP + TN) / (TP + TN + FP + FN) = (697 + 133) / (133 + 213 + 273 + 697) = 0.57

#No information rate = (714 + 216) / (714 + 216 + 258 + 137) = 0.701

```

##HYBRID RECOMMENDATION

```{r}

algorithms_SUMMARY <- list("Hybrid POPULAR + SVDF" = list(name = "HYBRID", param = list(recommenders = list(SVDF = list(name = "SVDF", param = list(k = 20)), POPULAR = list(name = "POPULAR", param = NULL)))),
  "Hybrid UBCF + SVDF" = list(name = "HYBRID", param = list(recommenders = list( SVDF = list(name = "SVDF", param = list(k = 20)), UBCF = list(name = "UBCF", param = list(nn = 45))))),
  "Hybrid UBCF + IBCF" = list(name = "HYBRID", param = list(recommenders = list( SVDF = list(name = "IBCF", param = list(k = 45)), UBCF = list(name = "UBCF", param = list(nn = 45))))))

# Estimate the Models in terms of accuracy of predictions
results_SUMMARY <- recommenderlab::evaluate(scheme_split,
                                    algorithms_SUMMARY, 
                                    type  = "ratings")

# Let's gather the results 
avg_conf_matr_SUMMARY <- function(results_SUMMARY) {
  tmp <- results_SUMMARY %>%
    getConfusionMatrix()  %>%  
    as.data.frame() %>%
    select('MAE', 'MSE', 'RMSE') 
}

#Print the results all together
results_summary_SUMMARY <- results_SUMMARY %>%
  map(avg_conf_matr_SUMMARY) %>% # iterate function across all models
  enframe() %>% 
  unnest() 

results_summary_SUMMARY

# Estimate the Models in terms of accuracy of classifications
results_SUMMARY1 <- recommenderlab::evaluate(scheme_split,
                                    algorithms_SUMMARY, 
                                    type  = "topNList", 
                                    n     = c(5, 10, 20)
                                    )

# Let's gather the results 
avg_conf_matr_SUMMARY1 <- function(results_SUMMARY1) {
  tmp <- results_SUMMARY1 %>%
    getConfusionMatrix()  %>%  
    as.data.frame() %>%
    select('n','precision', 'recall') 
}

#Print the results all together
results_summary_SUMMARY1 <- results_SUMMARY1 %>%
  map(avg_conf_matr_SUMMARY1) %>% # iterate function across all models
  enframe() %>% 
  unnest() 

results_summary_SUMMARY1

#In general terms, the best performing algorithm is Hybridization of SVDF computed with k = 20 and UBCF with nn = 45.

```

##FINDING POTENTIAL CUSTOMERS FOR RESTAURANTS

We will start by finding a list of recommendations per user usinng our best performing algorithm.

```{r}

# Create a ITEM-based collaborative filtering recommender
recommender_HYBRID <- Recommender(getData(scheme_split, "train"), "HYBRID", param = list(recommenders = list(SVDF = list(name = "SVDF", param = list(k = 20)), UBCF = list(name = "UBCF", param = list(nn = 45)))))

# Generate recommendations for a test set
recs_HYBRID <- predict(recommender_HYBRID, getData(scheme_split, "known"), type = "topNList", n = 5)

# Extract the actual recommendations from the list
recommendations_list_HYBRID <- as(recs_HYBRID, "list")
for (i in seq_along(recommendations_list_HYBRID)) {
  cat("User", i, "recommended items:", toString(recommendations_list_HYBRID[[i]]), "\n")}
  
```

Can we find potential customers for the restaurants? 

```{r}

# Initialize an empty list to store the restaurants and users
restaurants_users <- list()

# Iterate over each user in the main list
for (user in names(recommendations_list_HYBRID)) {
  # Get the list of restaurants for the current user
  restaurants <- recommendations_list_HYBRID[[user]]
  # Iterate over each restaurant for the current user
  for (restaurant in restaurants) {
    # Check if the restaurant already exists in the list
    if (restaurant %in% names(restaurants_users)) {
      # Append the current user to the existing restaurant entry
      restaurants_users[[restaurant]] <- c(restaurants_users[[restaurant]], user)
    } else {
      # Create a new entry for the restaurant and assign the current user
      restaurants_users[[restaurant]] <- list(user)
    }
  }
}

# Print the list of restaurants with the corresponding list of users
print(restaurants_users)

#We are able to find potential customers for a set of restaurants in the city of Aarhus, however, the list of matches we can generate is limitted in number.


```


#IV. RESULTS AND DISCUSSION

Can be found in the main project document.



END.